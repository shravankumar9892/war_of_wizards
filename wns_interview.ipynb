{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wns_interview.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shravankumar9892/war_of_wizards/blob/master/wns_interview.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "b_qSBgByE9Un",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Authenticatioon + fetching data"
      ]
    },
    {
      "metadata": {
        "id": "r9sXLpCpEew_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python import keras # Use keras.layers. to make the neural network\n",
        "import shutil\n",
        "\n",
        "# gpu \n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V-Xz7jaaFha0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xfwtmOdmFvtQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_downloaded = drive.CreateFile({'id':'1sJ6TOntkRu1WXGm15I1AUqItAmKoA49i'})\n",
        "train_downloaded.GetContentFile('train_LZdllcl.csv')\n",
        "test_downloaded = drive.CreateFile({'id':'1kBx6SWGFHZ3QmwkxnDjSLr9PWI7bDccL'})\n",
        "test_downloaded.GetContentFile('test_2umaH9m.csv')\n",
        "\n",
        "df_train = pd.read_csv('train_LZdllcl.csv')\n",
        "df_test = pd.read_csv('test_2umaH9m.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkACwW5DKtTu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing + splitting"
      ]
    },
    {
      "metadata": {
        "id": "XaweRz0NyeNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NaN values in test data\n",
        "y_train = df_train['is_promoted']\n",
        "X_train = df_train[['department', 'education', 'gender', 'recruitment_channel', 'no_of_trainings', 'age', 'previous_year_rating', 'length_of_service', 'KPIs_met_80', 'awards_won', 'avg_training_score']]\n",
        "X_test = df_test[['department', 'education', 'gender', 'recruitment_channel', 'no_of_trainings', 'age', 'previous_year_rating', 'length_of_service', 'KPIs_met_80', 'awards_won', 'avg_training_score']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5vmSOLs7WYzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Filling in NaN values\n",
        "X_train['previous_year_rating'].fillna(0, inplace = True)\n",
        "X_test['previous_year_rating'].fillna(0, inplace = True)\n",
        "\n",
        "X_train.fillna(X_train.min(), inplace = True)\n",
        "X_test.fillna(X_test.min(), inplace = True)\n",
        "\n",
        "# department\n",
        "X_train['department'] = le.fit_transform(X_train['department'].astype('str'))\n",
        "X_test['department'] = le.fit_transform(X_test['department'].astype('str'))\n",
        "\n",
        "# gender\n",
        "X_train['gender'] = le.fit_transform(X_train['gender'].astype('str'))\n",
        "X_test['gender'] = le.fit_transform(X_test['gender'].astype('str'))\n",
        "\n",
        "# recruitment_channel\n",
        "X_train['recruitment_channel'] = le.fit_transform(X_train['recruitment_channel'].astype('str'))\n",
        "X_test['recruitment_channel'] = le.fit_transform(X_test['recruitment_channel'].astype('str'))\n",
        "\n",
        "# education\n",
        "X_train['education'] = le.fit_transform(X_train['education'].astype('str'))\n",
        "X_test['education'] = le.fit_transform(X_test['education'].astype('str'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYpds6JFMyLe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "metadata": {
        "id": "XTtV9Y7xMxju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train['avg_training_score'] = X_train['avg_training_score']**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZwHS11avtK5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create validation data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.3, random_state = 3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ylo9ixFeUOah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorBoard"
      ]
    },
    {
      "metadata": {
        "id": "OuDc3RBFUR8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpbp-_zFUdip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './outdir'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4MuVFupUkQc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "plavA4LRUp_b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QM-cgACzVbuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./outdir', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=128,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yw0XtqUxKXXx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow "
      ]
    },
    {
      "metadata": {
        "id": "ktWjMQvTybo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Second approach for input pipelines\n",
        "\n",
        "def make_input_fn(X, y, num_epochs):\n",
        "  return tf.estimator.inputs.pandas_input_fn(\n",
        "    x = X,\n",
        "    y = y,\n",
        "    batch_size = 128,\n",
        "    num_epochs = num_epochs,\n",
        "    shuffle = True,\n",
        "    queue_capacity = 1000,\n",
        "    num_threads = 1\n",
        "  )\n",
        "\n",
        "def make_prediction_input_fn(X, num_epochs):\n",
        "  return tf.estimator.inputs.pandas_input_fn(\n",
        "    x = X,\n",
        "    y = None,\n",
        "    batch_size = 128,\n",
        "    num_epochs = num_epochs,\n",
        "    shuffle = True,\n",
        "    queue_capacity = 1000,\n",
        "    num_threads = 1\n",
        "  )\n",
        "\n",
        "def make_feature_cols():\n",
        "    categorical_column = tf.feature_column.categorical_column_with_vocabulary_list(key=\"Sex\", vocabulary_list=[\"male\", \"female\"], default_value=0)\n",
        "    return [tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(key = 'department', vocabulary_list=[0,1,2,3,4,5,6,7,8], default_value = 0)),\\\n",
        "            tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(key = 'recruitment_channel', vocabulary_list=[0,1,2])),\\\n",
        "            tf.feature_column.numeric_column(\"no_of_trainings\"),\\\n",
        "            tf.feature_column.numeric_column(\"age\"),\\\n",
        "            tf.feature_column.numeric_column(\"previous_year_rating\"),\\\n",
        "            tf.feature_column.numeric_column(\"length_of_service\"),\\\n",
        "            tf.feature_column.numeric_column(\"KPIs_met_80\"),\\\n",
        "            tf.feature_column.numeric_column(\"awards_won\"),\\\n",
        "            tf.feature_column.numeric_column(\"avg_training_score\")\n",
        "           ] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4hvA1DW2m-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "output_dir = './outdir'\n",
        "shutil.rmtree(output_dir, ignore_errors = True) # start fresh each time\n",
        "#model = tf.estimator.LinearClassifier(\n",
        "#      feature_columns = make_feature_cols(), model_dir = output_dir, optimizer = optimizer, n_classes = 2)\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "def metric_auc(labels, predictions):\n",
        "    return {\n",
        "        'auc_precision_recall': tf.metrics.auc(\n",
        "            labels=labels, predictions=predictions['logistic'], num_thresholds=200,\n",
        "            curve='PR', summation_method='careful_interpolation')\n",
        "    }\n",
        "\n",
        "  \n",
        "optimizer=tf.train.AdamOptimizer()\n",
        "\n",
        "model = tf.estimator.DNNClassifier(hidden_units = [8, 6, 4, 3],\n",
        "      feature_columns = make_feature_cols(), optimizer = optimizer, model_dir = output_dir)\n",
        "model = tf.contrib.estimator.add_metrics(model, metric_auc)\n",
        "with tf.device('/gpu:0'):\n",
        "  model.train(input_fn = make_input_fn(X = X_train, y = y_train, num_epochs = int(input(\"Enter number of epochs:\"))), callbacks=[tbCallBack])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JCwE3Bb-26yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_rmse(model, name, X, y):\n",
        "  metrics = model.evaluate(input_fn = make_input_fn(X, y, 1))\n",
        "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
        "  print('f1_score on {} dataset = {}'.format(name, (2*metrics['precision']*metrics['recall']/(metrics['precision'] + metrics['recall']))))\n",
        "print_rmse(model, 'validation', X_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gVNKZZCX4uG7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Prediction Time :**"
      ]
    },
    {
      "metadata": {
        "id": "hKtVHK_43udY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generator object\n",
        "pred = []\n",
        "predictions = model.predict(input_fn = make_prediction_input_fn(X_test, 1))\n",
        "n = list(predictions)\n",
        "for i in range(len(n)):\n",
        "  pred.append(n[i][\"logits\"][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utHU4lnJ58sR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating Submission file\n",
        "from google.colab import files\n",
        "\n",
        "employee_id = np.asarray(df_test.employee_id)\n",
        "df = pd.DataFrame({'employee_id':employee_id, 'is_promoted':np.asarray(ans1)})\n",
        "\n",
        "df.to_csv(path_or_buf = 'predictions_hack_education_included.csv', index = False, sep = ',')\n",
        "from google.colab import files\n",
        "files.download('predictions_hack_education_included.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}